{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras as k\n",
    "import theano as th\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random model search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.15119496  0.58573944  0.73130289 -0.28085152] 10.0\n",
      "[-1.98039047 -0.61032615  1.79320846  0.83351369] 70.0\n",
      "[ 0.15765545 -1.26804802 -0.99818049  2.41966705] 104.0\n",
      "[-1.00149121 -0.53527773  1.26530749  1.04247018] 145.0\n",
      "[-0.22410222  0.10800922 -0.44457193  0.97412923] 200.0\n"
     ]
    }
   ],
   "source": [
    "s = env.reset()\n",
    "\n",
    "best_model = np.zeros(4)\n",
    "best_result = 0\n",
    "\n",
    "for i in range(1000):\n",
    "    s = env.reset()\n",
    "    done = False\n",
    "    model = np.random.randn(4)\n",
    "    model_result = 0\n",
    "\n",
    "    while not done:\n",
    "        a = int(0<model.dot(s))\n",
    "        s, r, done, _ = env.step(a)\n",
    "        model_result += r\n",
    "        \n",
    "    if best_result < model_result:\n",
    "        best_result = model_result\n",
    "        best_model = model.copy()\n",
    "        print(best_model, best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.22410222,  0.10800922, -0.44457193,  0.97412923])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = env.reset()\n",
    "done = False\n",
    "img = plt.imshow(env.render(mode='rgb_array')) # only call this once\n",
    "while not done:\n",
    "    img.set_data(env.render(mode='rgb_array')) # just update the data\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    action = int(0<best_model.dot(s))\n",
    "    s, r, done, _ = env.step(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-200.0\n"
     ]
    }
   ],
   "source": [
    "from gym import wrappers\n",
    "env_video = wrappers.Monitor(env, 'video_test_mountaincar')\n",
    "s = env_video.reset()\n",
    "done = False\n",
    "play_result = 0\n",
    "\n",
    "while not done:\n",
    "    action, Qsa = m.predict(s)\n",
    "    s, r, done, _ = env_video.step(action)\n",
    "    play_result += r\n",
    "    \n",
    "print(play_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q_learning bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating states to detemrine extreme values for keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_simulations(env, nb_it=100):\n",
    "    states = env.reset()\n",
    "    states = states.reshape((4, 1))\n",
    "    \n",
    "    for i in range(nb_it):\n",
    "        s = env.reset()\n",
    "        done = False\n",
    "        model = np.random.randn(4)\n",
    "        model_result = 0\n",
    "\n",
    "        while not done:\n",
    "            a = int(0<model.dot(s))\n",
    "            s, r, done, _ = env.step(a)\n",
    "            s = s.reshape((4, 1))\n",
    "            \n",
    "            states = np.concatenate([states, s], axis=1)\n",
    "\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_uniformely_distributed_intervals(state_list, nb_interval=10, hardcoded=True):\n",
    "    \n",
    "    nb_var = state_list.shape[0]\n",
    "    \n",
    "    if not hardcoded:\n",
    "        dimensions_step = np.array((np.amax(state_list, axis=1)-np.amin(state_list, axis=1))/nb_interval)\n",
    "        intervals = np.amin(state_list, axis=1)\n",
    "        next_interval = np.amin(state_list, axis=1)\n",
    "    else:\n",
    "        dimensions_step = (np.array([2.4, 2, 0.4, 3.5])-np.array([-2.4, -2, -0.4, -3.5]))/nb_interval\n",
    "        intervals = np.array([-2.4, -2, -0.4, -3.5])\n",
    "        next_interval = np.array([-2.4, -2, -0.4, -3.5])\n",
    "    \n",
    "    for i in range(nb_interval):\n",
    "        next_interval = next_interval+dimensions_step\n",
    "        intervals = np.concatenate([intervals, next_interval], axis=0)\n",
    "                \n",
    "    return intervals.reshape((nb_interval+1, nb_var)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_dict(d):\n",
    "    k = max(d, key=lambda x: d[x])\n",
    "    return k, d[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy(a, eps):\n",
    "    p = np.random.rand()\n",
    "    if p < eps:\n",
    "        return np.random.randint(env.action_space.n)\n",
    "    else:\n",
    "        return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oragnising the the state/action pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full generation of the state acion dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_key_from_interval_values(intervals_values):\n",
    "    return itertools.product(*intervals_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_key(state, Q_dict):\n",
    "    return min(Q_dict, key=lambda x: np.sum([(x[i]-state[i])**2 for i, e in enumerate(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_Q_values(keys, all_possible_actions, visit_counter=True):\n",
    "    Q_values_dict = dict()\n",
    "    if visit_counter: update_count = dict()\n",
    "    for k in keys:\n",
    "        Q_values_dict[k] = dict()\n",
    "        if visit_counter: update_count[k] = dict()\n",
    "        for a in range(all_possible_actions):\n",
    "            Q_values_dict[k][a] = 0\n",
    "            update_count[k][a] = 1\n",
    "    return Q_values_dict, update_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn(s, Q_values):\n",
    "    s_k = state_to_key(s, Q_values)\n",
    "    a, v = max_dict(Q_values[s_k])\n",
    "    a = epsilon_greedy(a)\n",
    "    s2, r, done, _ = env.step(a)\n",
    "    s2_k = state_to_key(s2, Q_values)\n",
    "    a2, v2 = max_dict(Q_values[s2_k])\n",
    "    a2 = epsilon_greedy(a2)\n",
    "    return s_k, a, r, s2_k, a2, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_Q(Q, s_k, a, r, s2_k, alpha, gamma, a2=None, update_count=None):\n",
    "    if not a2: a2, max_q_sa2 = max_dict(Q[s2_k])\n",
    "    if update_count: alpha = alpha/update_count[s_k][a]\n",
    "    Q[s_k][a] = Q[s_k][a] + alpha*(r + gamma*max_q_sa2 - Q[s_k][a])\n",
    "    if update_count:\n",
    "        update_count[s_k][a] += 0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree organisation of satte/action pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subtree(total_depht, current_depht, key, subtree, actions):\n",
    "    if total_depht==current_depht:\n",
    "        for a in range(actions):\n",
    "            subtree[a] = 0\n",
    "    else:\n",
    "        k = key[current_depht]\n",
    "        if k in subtree:\n",
    "            return create_subtree(total_depht, current_depht+1, key, subtree[k], actions)\n",
    "        else:\n",
    "            subtree[k] = dict()\n",
    "            create_subtree(total_depht, current_depht+1, key, subtree[k], actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_Q_values_tree(keys, all_possible_actions, visit_counter=True):\n",
    "    Q = dict()\n",
    "    if visit_counter==True: update_count=dict()\n",
    "    for k in keys:\n",
    "        total_depht = len(k)\n",
    "        create_subtree(total_depht, 0, k, Q, all_possible_actions)\n",
    "        create_subtree(total_depht, 0, k, update_count, all_possible_actions)\n",
    "    return Q, update_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_subtree_key(value, subtree):\n",
    "    key = min(subtree, key=lambda x: (x-value)**2)\n",
    "    return key, subtree[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def access_subtree(s, tree):\n",
    "    subtree = tree\n",
    "    for e in s:\n",
    "        k, subtree = search_subtree_key(e, subtree)\n",
    "    return subtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn(s, Q_values, eps):\n",
    "    a, v = max_dict(access_subtree(s, Q_values))\n",
    "    a = epsilon_greedy(a, eps=eps)\n",
    "    s2, r, done, _ = env.step(a)\n",
    "    return s, a, v, r, s2, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_Q(Q, s, a, v, r, s2, alpha, gamma, a2=None, update_count=None):\n",
    "    if not a2: a2, max_q_sa2 = max_dict(access_subtree(s2, Q))\n",
    "    if update_count: alpha = alpha/(1+access_subtree(s, update_count)[a])\n",
    "    v = v + alpha*(r + gamma*max_q_sa2 - v)\n",
    "    Qs = access_subtree(s, Q)\n",
    "    Qs[a] = v\n",
    "    if update_count:\n",
    "        counts = access_subtree(s, update_count)\n",
    "        counts[a] += 0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions playing play the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_episode(env, Q, update_count, alpha=0.1, gamma=0.9, eps=0.8):\n",
    "    s = env.reset()\n",
    "    done = False\n",
    "    total_result = 0\n",
    "    \n",
    "    while not done:\n",
    "        s, a, v, r, s2, done = turn(s, Q, eps)\n",
    "        if done and total_result<198:\n",
    "            r = -300\n",
    "        update_Q(Q, s, a, v, r, s2, alpha, gamma, update_count=update_count)\n",
    "        s = s2\n",
    "        total_result += 1\n",
    "    \n",
    "    return total_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_Q(env):\n",
    "    #states = run_random_simulations(env, nb_it=10000)\n",
    "    intervals_values = generate_uniformely_distributed_intervals(states)\n",
    "    keys = gen_key_from_interval_values(intervals_values)\n",
    "    Q, update_count = initialise_Q_values_tree(keys, env.action_space.n)\n",
    "    return Q, update_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_env(env, alpha, gamma, nb_episode=10000):\n",
    "    Q, update_count = initialise_Q(env)\n",
    "    last_100_episodes_result = []\n",
    "    \n",
    "    for i in range(nb_episode):\n",
    "        eps = 1.0/np.sqrt(i+1)\n",
    "        tot_res = play_episode(env, Q, update_count, alpha, gamma, eps)\n",
    "        last_100_episodes_result.append(tot_res)\n",
    "        if (i+1)%100==0:\n",
    "            print('%i/%i: %f.2'%(i+1, nb_episode, np.mean(last_100_episodes_result )))\n",
    "            last_100_episodes_result = []\n",
    "    \n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/10000: 21.350000.2\n",
      "200/10000: 26.620000.2\n",
      "300/10000: 24.760000.2\n",
      "400/10000: 40.630000.2\n",
      "500/10000: 61.380000.2\n",
      "600/10000: 65.960000.2\n",
      "700/10000: 85.290000.2\n",
      "800/10000: 77.300000.2\n",
      "900/10000: 74.710000.2\n",
      "1000/10000: 83.830000.2\n",
      "1100/10000: 78.950000.2\n",
      "1200/10000: 108.410000.2\n",
      "1300/10000: 118.200000.2\n",
      "1400/10000: 105.140000.2\n",
      "1500/10000: 118.400000.2\n",
      "1600/10000: 122.680000.2\n",
      "1700/10000: 128.190000.2\n",
      "1800/10000: 123.100000.2\n",
      "1900/10000: 131.400000.2\n",
      "2000/10000: 121.510000.2\n",
      "2100/10000: 147.080000.2\n",
      "2200/10000: 146.820000.2\n",
      "2300/10000: 137.530000.2\n",
      "2400/10000: 134.700000.2\n",
      "2500/10000: 148.420000.2\n",
      "2600/10000: 158.110000.2\n",
      "2700/10000: 143.660000.2\n",
      "2800/10000: 138.200000.2\n",
      "2900/10000: 143.390000.2\n",
      "3000/10000: 164.840000.2\n",
      "3100/10000: 147.570000.2\n",
      "3200/10000: 173.050000.2\n",
      "3300/10000: 167.440000.2\n",
      "3400/10000: 166.830000.2\n",
      "3500/10000: 163.010000.2\n",
      "3600/10000: 167.940000.2\n",
      "3700/10000: 156.670000.2\n",
      "3800/10000: 150.130000.2\n",
      "3900/10000: 165.830000.2\n",
      "4000/10000: 164.310000.2\n",
      "4100/10000: 165.720000.2\n",
      "4200/10000: 164.620000.2\n",
      "4300/10000: 179.820000.2\n",
      "4400/10000: 177.570000.2\n",
      "4500/10000: 167.240000.2\n",
      "4600/10000: 158.860000.2\n",
      "4700/10000: 161.590000.2\n",
      "4800/10000: 152.940000.2\n",
      "4900/10000: 156.200000.2\n",
      "5000/10000: 176.290000.2\n",
      "5100/10000: 179.760000.2\n",
      "5200/10000: 173.520000.2\n",
      "5300/10000: 182.890000.2\n",
      "5400/10000: 181.010000.2\n",
      "5500/10000: 181.410000.2\n",
      "5600/10000: 176.660000.2\n",
      "5700/10000: 188.820000.2\n",
      "5800/10000: 176.930000.2\n",
      "5900/10000: 189.900000.2\n",
      "6000/10000: 178.070000.2\n",
      "6100/10000: 182.160000.2\n",
      "6200/10000: 181.800000.2\n",
      "6300/10000: 179.070000.2\n",
      "6400/10000: 165.830000.2\n",
      "6500/10000: 176.070000.2\n",
      "6600/10000: 177.010000.2\n",
      "6700/10000: 182.620000.2\n",
      "6800/10000: 159.330000.2\n",
      "6900/10000: 181.720000.2\n",
      "7000/10000: 165.890000.2\n",
      "7100/10000: 164.580000.2\n",
      "7200/10000: 174.430000.2\n",
      "7300/10000: 185.290000.2\n",
      "7400/10000: 187.660000.2\n",
      "7500/10000: 193.650000.2\n",
      "7600/10000: 171.800000.2\n",
      "7700/10000: 184.060000.2\n",
      "7800/10000: 181.000000.2\n",
      "7900/10000: 189.690000.2\n",
      "8000/10000: 182.220000.2\n",
      "8100/10000: 178.140000.2\n",
      "8200/10000: 173.560000.2\n",
      "8300/10000: 170.340000.2\n",
      "8400/10000: 164.370000.2\n",
      "8500/10000: 179.540000.2\n",
      "8600/10000: 162.420000.2\n",
      "8700/10000: 167.400000.2\n",
      "8800/10000: 185.590000.2\n",
      "8900/10000: 181.460000.2\n",
      "9000/10000: 184.280000.2\n",
      "9100/10000: 190.670000.2\n",
      "9200/10000: 181.820000.2\n",
      "9300/10000: 183.190000.2\n",
      "9400/10000: 183.140000.2\n",
      "9500/10000: 183.710000.2\n",
      "9600/10000: 191.540000.2\n",
      "9700/10000: 191.450000.2\n",
      "9800/10000: 183.570000.2\n",
      "9900/10000: 186.850000.2\n",
      "10000/10000: 177.890000.2\n"
     ]
    }
   ],
   "source": [
    "Q = learning_env(env, 0.01, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### GG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBF_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer():\n",
    "    \n",
    "    def __init__(self, env, n_components=500):\n",
    "        self.std_scaler = StandardScaler()\n",
    "        self.rbf_transformer = FeatureUnion([\n",
    "            (\"rbf1\", RBFSampler(gamma=5.0, n_components=n_components)),\n",
    "            (\"rbf2\", RBFSampler(gamma=2.0, n_components=n_components)),\n",
    "            (\"rbf3\", RBFSampler(gamma=1.0, n_components=n_components)),\n",
    "            (\"rbf4\", RBFSampler(gamma=0.5, n_components=n_components))\n",
    "            ])\n",
    "        sample_states = np.array([env.observation_space.sample() for x in range(10000)])\n",
    "        self.std_scaler.fit(sample_states)\n",
    "        normalized_states = self.std_scaler.transform(sample_states)\n",
    "        self.rbf_transformer.fit(normalized_states)\n",
    "        \n",
    "    def transform(self, data):\n",
    "        normalized_data = self.std_scaler.transform(data)\n",
    "        return self.rbf_transformer.transform(normalized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    \n",
    "    def __init__(self, env, feature_transformer, learning_rate, gamma=0.99):\n",
    "        self.feature_transformer = feature_transformer\n",
    "        self.gamma = gamma\n",
    "        self.models = []\n",
    "        for i in range(env.action_space.n):\n",
    "            model = SGDRegressor(learning_rate=learning_rate)\n",
    "            init_s_val = env.observation_space.sample()\n",
    "            transf_init_s_val = self.feature_transformer.transform([init_s_val])\n",
    "            model.partial_fit(transf_init_s_val, [0])\n",
    "            self.models.append(model)\n",
    "            \n",
    "    def predict(self, raw_state):\n",
    "        transformed_state = self.feature_transformer.transform([raw_state])\n",
    "        results = np.stack([m.predict(transformed_state) for m in self.models]).T\n",
    "        a = np.argmax(results)\n",
    "        return a, results[0][a]\n",
    "    \n",
    "    def update_model(self, s, a, r, s2):\n",
    "        a2, max_qs2 = self.predict(s2)\n",
    "        G = r + self.gamma*max_qs2\n",
    "        s_transformed = self.feature_transformer.transform([s])\n",
    "        self.models[a].partial_fit(s_transformed, [G])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy(a, eps):\n",
    "    p = np.random.rand()\n",
    "    if p < eps:\n",
    "        return env.action_space.sample()\n",
    "    else:\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn(env, model, s, eps):\n",
    "    a, Qsa = model.predict(s)\n",
    "    a = epsilon_greedy(a, eps)\n",
    "    s2, r, done, _ = env.step(a)\n",
    "    model.update_model(s, a, r, s2)\n",
    "    return s2, r, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one(env, model, eps=0.5):\n",
    "    s = env.reset()\n",
    "    done = False\n",
    "    result = 0\n",
    "    it = 0\n",
    "    \n",
    "    while not done and it<10000:\n",
    "        s, r, done = turn(env, model, s, eps)\n",
    "        result += r\n",
    "        it += 1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(env, nb_episode):\n",
    "    ft_transf = Transformer(env)\n",
    "    model = Model(env, ft_transf, \"constant\")\n",
    "    \n",
    "    avg = []\n",
    "    \n",
    "    for n in range(nb_episode):\n",
    "        eps = 0.1*(0.97**n)\n",
    "        #eps = (1 - (n+1)/nb_episode)\n",
    "        r = play_one(env, model, eps)\n",
    "        avg.append(r)\n",
    "        \n",
    "        if not (n+1)%30:\n",
    "            print('%i/%i: %f.2, eps = %f.2'%(n+1, nb_episode, np.mean(avg), eps))\n",
    "            avg = []\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/300: -200.000000.2, eps = 0.041341.2\n",
      "60/300: -171.933333.2, eps = 0.016578.2\n",
      "90/300: -140.933333.2, eps = 0.006648.2\n",
      "120/300: -131.766667.2, eps = 0.002666.2\n",
      "150/300: -117.800000.2, eps = 0.001069.2\n",
      "180/300: -114.800000.2, eps = 0.000429.2\n",
      "210/300: -105.633333.2, eps = 0.000172.2\n",
      "240/300: -108.700000.2, eps = 0.000069.2\n",
      "270/300: -109.233333.2, eps = 0.000028.2\n",
      "300/300: -117.166667.2, eps = 0.000011.2\n"
     ]
    }
   ],
   "source": [
    "m = main(env, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = env.reset()\n",
    "done = False\n",
    "img = plt.imshow(env.render(mode='rgb_array')) # only call this once\n",
    "while not done:\n",
    "    img.set_data(env.render(mode='rgb_array')) # just update the data\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    action, Qsa = m.predict(s)\n",
    "    s, r, done, _ = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/300: -200.000000.2, eps = 0.041341.2\n",
      "60/300: -178.633333.2, eps = 0.016578.2\n",
      "90/300: -143.966667.2, eps = 0.006648.2\n",
      "120/300: -131.733333.2, eps = 0.002666.2\n",
      "150/300: -121.266667.2, eps = 0.001069.2\n",
      "180/300: -116.200000.2, eps = 0.000429.2\n",
      "210/300: -109.733333.2, eps = 0.000172.2\n",
      "240/300: -112.700000.2, eps = 0.000069.2\n",
      "270/300: -113.800000.2, eps = 0.000028.2\n",
      "300/300: -116.200000.2, eps = 0.000011.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Model at 0x7fbb67154550>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main(env, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recoding the SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer():\n",
    "    \n",
    "    def __init__(self, env, n_components=500):\n",
    "        self.std_scaler = StandardScaler()\n",
    "        self.rbf_transformer = FeatureUnion([\n",
    "            (\"rbf1\", RBFSampler(gamma=0.05, n_components=n_components)),\n",
    "            (\"rbf2\", RBFSampler(gamma=1.0, n_components=n_components)),\n",
    "            (\"rbf3\", RBFSampler(gamma=0.5, n_components=n_components)),\n",
    "            (\"rbf4\", RBFSampler(gamma=0.1, n_components=n_components))\n",
    "            ])\n",
    "        sample_states = np.array([env.observation_space.sample() for x in range(10000)])\n",
    "        sample_states = np.array([[np.random.uniform(-2.4, 2.4), np.random.uniform(-2, 2), np.random.uniform(-0.4, 0.4), np.random.uniform(-3.5, 3.5)] for x in range(10000)])\n",
    "        self.std_scaler.fit(sample_states)\n",
    "        normalized_states = self.std_scaler.transform(sample_states)\n",
    "        self.rbf_transformer.fit(normalized_states)\n",
    "        self.dimensions = self.rbf_transformer.transform(normalized_states).shape[1]\n",
    "        \n",
    "    def transform(self, data):\n",
    "        normalized_data = self.std_scaler.transform(data)\n",
    "        return self.rbf_transformer.transform(normalized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(env, nb_episode):\n",
    "    ft_transf = Transformer(env)\n",
    "    model = Model(env, ft_transf, \"constant\")\n",
    "    \n",
    "    avg = []\n",
    "    \n",
    "    for n in range(nb_episode):\n",
    "        #eps = 0.1*(0.97**n)\n",
    "        eps = (1 - (n+1)/nb_episode)\n",
    "        #eps = 0.8\n",
    "        r = play_one(env, model, eps)\n",
    "        avg.append(r)\n",
    "        \n",
    "        if not (n+1)%30:\n",
    "            print('%i/%i: %f.2, eps = %f.2'%(n+1, nb_episode, np.mean(avg), eps))\n",
    "            avg = []\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDRegressor():\n",
    "    def __init__(self, D):\n",
    "        self.D = np.random.randn(D) / np.sqrt(D)\n",
    "        self.lr = 0.1\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return X.dot(self.D)\n",
    "    \n",
    "    def partial_fit(self, X, Y):\n",
    "        self.D += self.lr*(Y - X.dot(self.D)).dot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    \n",
    "    def __init__(self, env, feature_transformer, learning_rate, gamma=0.99):\n",
    "        self.feature_transformer = feature_transformer\n",
    "        self.gamma = gamma\n",
    "        self.models = []\n",
    "        for i in range(env.action_space.n):\n",
    "            model = SGDRegressor(self.feature_transformer.dimensions)\n",
    "            init_s_val = env.observation_space.sample()\n",
    "            transf_init_s_val = self.feature_transformer.transform([init_s_val])\n",
    "            model.partial_fit(transf_init_s_val, [0])\n",
    "            self.models.append(model)\n",
    "            \n",
    "    def predict(self, raw_state):\n",
    "        transformed_state = self.feature_transformer.transform([raw_state])\n",
    "        results = np.stack([m.predict(transformed_state) for m in self.models]).T\n",
    "        a = np.argmax(results)\n",
    "        return a, results[0][a]\n",
    "    \n",
    "    def update_model(self, s, a, r, s2):\n",
    "        a2, max_qs2 = self.predict(s2)\n",
    "        G = r + self.gamma*max_qs2\n",
    "        s_transformed = self.feature_transformer.transform([s])\n",
    "        self.models[a].partial_fit(s_transformed, [G])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn(env, model, s, eps, current_score):\n",
    "    a, Qsa = model.predict(s)\n",
    "    a = epsilon_greedy(a, eps)\n",
    "    s2, r, done, _ = env.step(a)\n",
    "    if done and current_score<198:\n",
    "        r = -300\n",
    "    model.update_model(s, a, r, s2)\n",
    "    return s2, r, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_one(env, model, eps=0.5):\n",
    "    s = env.reset()\n",
    "    done = False\n",
    "    result = 0\n",
    "    it = 0\n",
    "    \n",
    "    while not done and it<10000:\n",
    "        s, r, done = turn(env, model, s, eps, result)\n",
    "        result += r\n",
    "        it += 1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/600: -276.433333.2, eps = 0.950000.2\n",
      "60/600: -272.933333.2, eps = 0.900000.2\n",
      "90/600: -271.733333.2, eps = 0.850000.2\n",
      "120/600: -271.733333.2, eps = 0.800000.2\n",
      "150/600: -263.400000.2, eps = 0.750000.2\n",
      "180/600: -249.700000.2, eps = 0.700000.2\n",
      "210/600: -243.733333.2, eps = 0.650000.2\n",
      "240/600: -228.566667.2, eps = 0.600000.2\n",
      "270/600: -209.866667.2, eps = 0.550000.2\n",
      "300/600: -154.066667.2, eps = 0.500000.2\n",
      "330/600: -93.566667.2, eps = 0.450000.2\n",
      "360/600: -81.600000.2, eps = 0.400000.2\n",
      "390/600: -82.633333.2, eps = 0.350000.2\n",
      "420/600: -71.200000.2, eps = 0.300000.2\n",
      "450/600: 44.700000.2, eps = 0.250000.2\n",
      "480/600: 146.433333.2, eps = 0.200000.2\n",
      "510/600: 151.833333.2, eps = 0.150000.2\n",
      "540/600: 147.700000.2, eps = 0.100000.2\n",
      "570/600: 200.000000.2, eps = 0.050000.2\n",
      "600/600: 200.000000.2, eps = 0.000000.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Model at 0x7f83ef2d83c8>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main(env, 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recoding the SGDRegressor with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDRegressor():\n",
    "\n",
    "    def __init__(self, D):\n",
    "        print(\"Hello TensorFlow!\")\n",
    "        lr = 0.1\n",
    "\n",
    "        # create inputs, targets, params\n",
    "        # matmul doesn't like when w is 1-D\n",
    "        # so we make it 2-D and then flatten the prediction\n",
    "        self.w = tf.Variable(tf.random_normal(shape=(D, 1)), name='w')\n",
    "        self.X = tf.placeholder(tf.float32, shape=(None, D), name='X')\n",
    "        self.Y = tf.placeholder(tf.float32, shape=(None,), name='Y')\n",
    "\n",
    "        # make prediction and cost\n",
    "        Y_hat = tf.reshape( tf.matmul(self.X, self.w), [-1] )\n",
    "        delta = self.Y - Y_hat\n",
    "        cost = tf.reduce_sum(delta * delta)\n",
    "\n",
    "        # ops we want to call later\n",
    "        self.train_op = tf.train.GradientDescentOptimizer(lr).minimize(cost)\n",
    "        self.predict_op = Y_hat\n",
    "\n",
    "        # start the session and initialize params\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.session = tf.InteractiveSession()\n",
    "        self.session.run(init)\n",
    "\n",
    "    def partial_fit(self, X, Y):\n",
    "        self.session.run(self.train_op, feed_dict={self.X: X, self.Y: Y})\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.session.run(self.predict_op, feed_dict={self.X: X})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello TensorFlow!\n",
      "Hello TensorFlow!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/600: -277.433333.2, eps = 0.950000.2\n",
      "60/600: -277.500000.2, eps = 0.900000.2\n",
      "90/600: -277.133333.2, eps = 0.850000.2\n",
      "120/600: -266.900000.2, eps = 0.800000.2\n",
      "150/600: -266.466667.2, eps = 0.750000.2\n",
      "180/600: -247.066667.2, eps = 0.700000.2\n",
      "210/600: -245.400000.2, eps = 0.650000.2\n",
      "240/600: -218.166667.2, eps = 0.600000.2\n",
      "270/600: -213.700000.2, eps = 0.550000.2\n",
      "300/600: -230.333333.2, eps = 0.500000.2\n",
      "330/600: -223.366667.2, eps = 0.450000.2\n",
      "360/600: -148.666667.2, eps = 0.400000.2\n",
      "390/600: -122.766667.2, eps = 0.350000.2\n",
      "420/600: -100.033333.2, eps = 0.300000.2\n",
      "450/600: -91.300000.2, eps = 0.250000.2\n",
      "480/600: 11.766667.2, eps = 0.200000.2\n",
      "510/600: 90.133333.2, eps = 0.150000.2\n",
      "540/600: 122.766667.2, eps = 0.100000.2\n",
      "570/600: 175.133333.2, eps = 0.050000.2\n",
      "600/600: 188.433333.2, eps = 0.000000.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Model at 0x7f2c50afc748>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main(env, 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-length / TD(lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDRegressor():\n",
    "    def __init__(self, D):\n",
    "        self.D = np.random.randn(D) / np.sqrt(D)\n",
    "        self.lr = 0.1\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return X.dot(self.D)\n",
    "    \n",
    "    def partial_fit(self, X, Y, e):\n",
    "        self.D += self.lr*(Y - X.dot(self.D))*e[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    \n",
    "    def __init__(self, env, feature_transformer, learning_rate, gamma=0.99, lambda_=0.7):\n",
    "        self.feature_transformer = feature_transformer\n",
    "        self.gamma = gamma\n",
    "        self.lambda_ = lambda_\n",
    "        self.e = np.zeros((env.action_space.n, self.feature_transformer.dimensions))\n",
    "        self.models = []\n",
    "        for i in range(env.action_space.n):\n",
    "            model = SGDRegressor(self.feature_transformer.dimensions)\n",
    "            init_s_val = env.observation_space.sample()\n",
    "            self.models.append(model)\n",
    "            \n",
    "    def predict(self, raw_state):\n",
    "        transformed_state = self.feature_transformer.transform([raw_state])\n",
    "        results = np.stack([m.predict(transformed_state) for m in self.models]).T\n",
    "        a = np.argmax(results)\n",
    "        return a, results[0][a]\n",
    "    \n",
    "    def update_model(self, s, a, r, s2):\n",
    "        a2, max_qs2 = self.predict(s2)\n",
    "        G = r + self.gamma*max_qs2\n",
    "        s_transformed = self.feature_transformer.transform([s])\n",
    "        self.e *= self.gamma*self.lambda_\n",
    "        self.e[a] += s_transformed.reshape((2000,))\n",
    "        self.models[a].partial_fit(s_transformed, [G], self.e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/600: -279.666667.2, eps = 0.950000.2\n",
      "60/600: -270.833333.2, eps = 0.900000.2\n",
      "90/600: -273.666667.2, eps = 0.850000.2\n",
      "120/600: -272.266667.2, eps = 0.800000.2\n",
      "150/600: -264.600000.2, eps = 0.750000.2\n",
      "180/600: -254.566667.2, eps = 0.700000.2\n",
      "210/600: -235.066667.2, eps = 0.650000.2\n",
      "240/600: -211.033333.2, eps = 0.600000.2\n",
      "270/600: -200.033333.2, eps = 0.550000.2\n",
      "300/600: -195.333333.2, eps = 0.500000.2\n",
      "330/600: -87.100000.2, eps = 0.450000.2\n",
      "360/600: -166.866667.2, eps = 0.400000.2\n",
      "390/600: -37.533333.2, eps = 0.350000.2\n",
      "420/600: 33.100000.2, eps = 0.300000.2\n",
      "450/600: -16.300000.2, eps = 0.250000.2\n",
      "480/600: 96.333333.2, eps = 0.200000.2\n",
      "510/600: 174.333333.2, eps = 0.150000.2\n",
      "540/600: 185.700000.2, eps = 0.100000.2\n",
      "570/600: 200.000000.2, eps = 0.050000.2\n",
      "600/600: 200.000000.2, eps = 0.000000.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Model at 0x7f2a19c7f860>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main(env, 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Gradient method (actor critic method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDRegressor():\n",
    "\n",
    "    def __init__(self, D):\n",
    "        print(\"Hello TensorFlow!\")\n",
    "        lr = 0.1\n",
    "\n",
    "        # create inputs, targets, params\n",
    "        # matmul doesn't like when w is 1-D\n",
    "        # so we make it 2-D and then flatten the prediction\n",
    "        self.w = tf.Variable(tf.random_normal(shape=(D, 1)), name='w')\n",
    "        self.X = tf.placeholder(tf.float32, shape=(None, D), name='X')\n",
    "        self.Y = tf.placeholder(tf.float32, shape=(None,), name='Y')\n",
    "\n",
    "        # make prediction and cost\n",
    "        Y_hat = tf.reshape( tf.matmul(self.X, self.w), [-1] )\n",
    "        delta = self.Y - Y_hat\n",
    "        cost = tf.reduce_sum(delta * delta)\n",
    "\n",
    "        # ops we want to call later\n",
    "        self.train_op = tf.train.GradientDescentOptimizer(lr).minimize(cost)\n",
    "        self.predict_op = Y_hat\n",
    "\n",
    "        # start the session and initialize params\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.session = tf.InteractiveSession()\n",
    "        self.session.run(init)\n",
    "\n",
    "    def partial_fit(self, X, Y):\n",
    "        self.session.run(self.train_op, feed_dict={self.X: X, self.Y: Y})\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.session.run(self.predict_op, feed_dict={self.X: X})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
